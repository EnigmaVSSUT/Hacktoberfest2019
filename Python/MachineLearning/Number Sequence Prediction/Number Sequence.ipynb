{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using LSTM to predict the next digit of our sequence </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing the required libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Preparation</h4>\n",
    "<p> Here we are creating our own dataset consisting of number is a sequence(increasing order) <br>\n",
    "For example:</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style = \"text-align: center\">X</th>\n",
    "        <th>y</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>0 1 2 3 4</th>\n",
    "        <th>5</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>1 2 3 4 5</th>\n",
    "        <th>6</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>2 3 4 5 6</th>\n",
    "        <th>7</th>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = [[[(i + j)/150] for i in range(5)] for j in range(100)]\n",
    "target = [(i+5)/150 for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all to numpy arrays\n",
    "data = np.array(Data, dtype = float)\n",
    "target = np.array(target, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data to test and train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM((1), batch_input_shape = (None, 5, 1),return_sequences = True))\n",
    "# Adding a second layer of LSTM\n",
    "model.add(LSTM((1), return_sequences=False))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer= 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/600\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.3482 - acc: 0.0000e+00 - val_loss: 0.2783 - val_acc: 0.0000e+00\n",
      "Epoch 2/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3459 - acc: 0.0000e+00 - val_loss: 0.2761 - val_acc: 0.0000e+00\n",
      "Epoch 3/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3436 - acc: 0.0000e+00 - val_loss: 0.2738 - val_acc: 0.0000e+00\n",
      "Epoch 4/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.3413 - acc: 0.0000e+00 - val_loss: 0.2715 - val_acc: 0.0000e+00\n",
      "Epoch 5/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.3389 - acc: 0.0000e+00 - val_loss: 0.2691 - val_acc: 0.0000e+00\n",
      "Epoch 6/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.3365 - acc: 0.0000e+00 - val_loss: 0.2668 - val_acc: 0.0000e+00\n",
      "Epoch 7/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.3341 - acc: 0.0000e+00 - val_loss: 0.2643 - val_acc: 0.0000e+00\n",
      "Epoch 8/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.3316 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0000e+00\n",
      "Epoch 9/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.3291 - acc: 0.0000e+00 - val_loss: 0.2594 - val_acc: 0.0000e+00\n",
      "Epoch 10/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.3266 - acc: 0.0000e+00 - val_loss: 0.2569 - val_acc: 0.0000e+00\n",
      "Epoch 11/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.3240 - acc: 0.0000e+00 - val_loss: 0.2543 - val_acc: 0.0000e+00\n",
      "Epoch 12/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.3214 - acc: 0.0000e+00 - val_loss: 0.2517 - val_acc: 0.0000e+00\n",
      "Epoch 13/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.3187 - acc: 0.0000e+00 - val_loss: 0.2490 - val_acc: 0.0000e+00\n",
      "Epoch 14/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.3160 - acc: 0.0000e+00 - val_loss: 0.2463 - val_acc: 0.0000e+00\n",
      "Epoch 15/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.3132 - acc: 0.0000e+00 - val_loss: 0.2435 - val_acc: 0.0000e+00\n",
      "Epoch 16/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.3104 - acc: 0.0000e+00 - val_loss: 0.2407 - val_acc: 0.0000e+00\n",
      "Epoch 17/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.3076 - acc: 0.0000e+00 - val_loss: 0.2379 - val_acc: 0.0000e+00\n",
      "Epoch 18/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.3047 - acc: 0.0000e+00 - val_loss: 0.2350 - val_acc: 0.0000e+00\n",
      "Epoch 19/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.3018 - acc: 0.0000e+00 - val_loss: 0.2320 - val_acc: 0.0000e+00\n",
      "Epoch 20/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.2990 - acc: 0.0000e+00 - val_loss: 0.2291 - val_acc: 0.0000e+00\n",
      "Epoch 21/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.2960 - acc: 0.0000e+00 - val_loss: 0.2263 - val_acc: 0.0000e+00\n",
      "Epoch 22/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.2931 - acc: 0.0000e+00 - val_loss: 0.2235 - val_acc: 0.0000e+00\n",
      "Epoch 23/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.2901 - acc: 0.0000e+00 - val_loss: 0.2206 - val_acc: 0.0000e+00\n",
      "Epoch 24/600\n",
      "80/80 [==============================] - 0s 475us/step - loss: 0.2871 - acc: 0.0000e+00 - val_loss: 0.2177 - val_acc: 0.0000e+00\n",
      "Epoch 25/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.2841 - acc: 0.0000e+00 - val_loss: 0.2148 - val_acc: 0.0000e+00\n",
      "Epoch 26/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.2811 - acc: 0.0000e+00 - val_loss: 0.2118 - val_acc: 0.0000e+00\n",
      "Epoch 27/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.2781 - acc: 0.0000e+00 - val_loss: 0.2088 - val_acc: 0.0000e+00\n",
      "Epoch 28/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2750 - acc: 0.0000e+00 - val_loss: 0.2057 - val_acc: 0.0000e+00\n",
      "Epoch 29/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2720 - acc: 0.0000e+00 - val_loss: 0.2027 - val_acc: 0.0000e+00\n",
      "Epoch 30/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2691 - acc: 0.0000e+00 - val_loss: 0.1995 - val_acc: 0.0000e+00\n",
      "Epoch 31/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.2660 - acc: 0.0000e+00 - val_loss: 0.1963 - val_acc: 0.0000e+00\n",
      "Epoch 32/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.2630 - acc: 0.0000e+00 - val_loss: 0.1931 - val_acc: 0.0000e+00\n",
      "Epoch 33/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2601 - acc: 0.0000e+00 - val_loss: 0.1898 - val_acc: 0.0000e+00\n",
      "Epoch 34/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.2570 - acc: 0.0000e+00 - val_loss: 0.1866 - val_acc: 0.0000e+00\n",
      "Epoch 35/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2541 - acc: 0.0000e+00 - val_loss: 0.1834 - val_acc: 0.0000e+00\n",
      "Epoch 36/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.2511 - acc: 0.0000e+00 - val_loss: 0.1804 - val_acc: 0.0000e+00\n",
      "Epoch 37/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.1773 - val_acc: 0.0000e+00\n",
      "Epoch 38/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.2451 - acc: 0.0000e+00 - val_loss: 0.1743 - val_acc: 0.0000e+00\n",
      "Epoch 39/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.2422 - acc: 0.0000e+00 - val_loss: 0.1712 - val_acc: 0.0000e+00\n",
      "Epoch 40/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.2392 - acc: 0.0000e+00 - val_loss: 0.1683 - val_acc: 0.0000e+00\n",
      "Epoch 41/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.2363 - acc: 0.0000e+00 - val_loss: 0.1654 - val_acc: 0.0000e+00\n",
      "Epoch 42/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.2331 - acc: 0.0000e+00 - val_loss: 0.1630 - val_acc: 0.0000e+00\n",
      "Epoch 43/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2303 - acc: 0.0000e+00 - val_loss: 0.1604 - val_acc: 0.0000e+00\n",
      "Epoch 44/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.2273 - acc: 0.0000e+00 - val_loss: 0.1578 - val_acc: 0.0000e+00\n",
      "Epoch 45/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.2242 - acc: 0.0000e+00 - val_loss: 0.1556 - val_acc: 0.0000e+00\n",
      "Epoch 46/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.2210 - acc: 0.0000e+00 - val_loss: 0.1534 - val_acc: 0.0000e+00\n",
      "Epoch 47/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.2179 - acc: 0.0000e+00 - val_loss: 0.1511 - val_acc: 0.0000e+00\n",
      "Epoch 48/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.2150 - acc: 0.0000e+00 - val_loss: 0.1488 - val_acc: 0.0000e+00\n",
      "Epoch 49/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.2121 - acc: 0.0000e+00 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
      "Epoch 50/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.2092 - acc: 0.0000e+00 - val_loss: 0.1445 - val_acc: 0.0000e+00\n",
      "Epoch 51/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.2063 - acc: 0.0000e+00 - val_loss: 0.1425 - val_acc: 0.0000e+00\n",
      "Epoch 52/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.2033 - acc: 0.0000e+00 - val_loss: 0.1405 - val_acc: 0.0000e+00\n",
      "Epoch 53/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.2005 - acc: 0.0000e+00 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
      "Epoch 54/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1979 - acc: 0.0000e+00 - val_loss: 0.1366 - val_acc: 0.0000e+00\n",
      "Epoch 55/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1952 - acc: 0.0000e+00 - val_loss: 0.1349 - val_acc: 0.0000e+00\n",
      "Epoch 56/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1924 - acc: 0.0000e+00 - val_loss: 0.1334 - val_acc: 0.0000e+00\n",
      "Epoch 57/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1900 - acc: 0.0000e+00 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
      "Epoch 58/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 288us/step - loss: 0.1874 - acc: 0.0000e+00 - val_loss: 0.1307 - val_acc: 0.0000e+00\n",
      "Epoch 59/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1848 - acc: 0.0000e+00 - val_loss: 0.1295 - val_acc: 0.0000e+00\n",
      "Epoch 60/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.1823 - acc: 0.0000e+00 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 61/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1800 - acc: 0.0000e+00 - val_loss: 0.1272 - val_acc: 0.0000e+00\n",
      "Epoch 62/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1776 - acc: 0.0000e+00 - val_loss: 0.1264 - val_acc: 0.0000e+00\n",
      "Epoch 63/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1752 - acc: 0.0000e+00 - val_loss: 0.1255 - val_acc: 0.0000e+00\n",
      "Epoch 64/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.1728 - acc: 0.0000e+00 - val_loss: 0.1247 - val_acc: 0.0000e+00\n",
      "Epoch 65/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.1706 - acc: 0.0000e+00 - val_loss: 0.1238 - val_acc: 0.0000e+00\n",
      "Epoch 66/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.1686 - acc: 0.0000e+00 - val_loss: 0.1229 - val_acc: 0.0000e+00\n",
      "Epoch 67/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.1662 - acc: 0.0000e+00 - val_loss: 0.1220 - val_acc: 0.0000e+00\n",
      "Epoch 68/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.1643 - acc: 0.0000e+00 - val_loss: 0.1211 - val_acc: 0.0000e+00\n",
      "Epoch 69/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1625 - acc: 0.0000e+00 - val_loss: 0.1202 - val_acc: 0.0000e+00\n",
      "Epoch 70/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1603 - acc: 0.0000e+00 - val_loss: 0.1197 - val_acc: 0.0000e+00\n",
      "Epoch 71/600\n",
      "80/80 [==============================] - 0s 500us/step - loss: 0.1587 - acc: 0.0000e+00 - val_loss: 0.1191 - val_acc: 0.0000e+00\n",
      "Epoch 72/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.1566 - acc: 0.0000e+00 - val_loss: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 73/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.1549 - acc: 0.0000e+00 - val_loss: 0.1182 - val_acc: 0.0000e+00\n",
      "Epoch 74/600\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.1531 - acc: 0.0000e+00 - val_loss: 0.1179 - val_acc: 0.0000e+00\n",
      "Epoch 75/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1515 - acc: 0.0000e+00 - val_loss: 0.1176 - val_acc: 0.0000e+00\n",
      "Epoch 76/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.1497 - acc: 0.0000e+00 - val_loss: 0.1171 - val_acc: 0.0000e+00\n",
      "Epoch 77/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.1480 - acc: 0.0000e+00 - val_loss: 0.1167 - val_acc: 0.0000e+00\n",
      "Epoch 78/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1464 - acc: 0.0000e+00 - val_loss: 0.1162 - val_acc: 0.0000e+00\n",
      "Epoch 79/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.1450 - acc: 0.0000e+00 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
      "Epoch 80/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1434 - acc: 0.0000e+00 - val_loss: 0.1156 - val_acc: 0.0000e+00\n",
      "Epoch 81/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.1418 - acc: 0.0000e+00 - val_loss: 0.1153 - val_acc: 0.0000e+00\n",
      "Epoch 82/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.1403 - acc: 0.0000e+00 - val_loss: 0.1149 - val_acc: 0.0000e+00\n",
      "Epoch 83/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.1388 - acc: 0.0000e+00 - val_loss: 0.1148 - val_acc: 0.0000e+00\n",
      "Epoch 84/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1372 - acc: 0.0000e+00 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
      "Epoch 85/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.1357 - acc: 0.0000e+00 - val_loss: 0.1143 - val_acc: 0.0000e+00\n",
      "Epoch 86/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1343 - acc: 0.0000e+00 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
      "Epoch 87/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.1327 - acc: 0.0000e+00 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
      "Epoch 88/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.1313 - acc: 0.0000e+00 - val_loss: 0.1133 - val_acc: 0.0000e+00\n",
      "Epoch 89/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.1297 - acc: 0.0000e+00 - val_loss: 0.1129 - val_acc: 0.0000e+00\n",
      "Epoch 90/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.1284 - acc: 0.0000e+00 - val_loss: 0.1124 - val_acc: 0.0000e+00\n",
      "Epoch 91/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.1268 - acc: 0.0000e+00 - val_loss: 0.1121 - val_acc: 0.0000e+00\n",
      "Epoch 92/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.1255 - acc: 0.0000e+00 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
      "Epoch 93/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.1240 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
      "Epoch 94/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.1224 - acc: 0.0000e+00 - val_loss: 0.1110 - val_acc: 0.0000e+00\n",
      "Epoch 95/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.1210 - acc: 0.0000e+00 - val_loss: 0.1104 - val_acc: 0.0000e+00\n",
      "Epoch 96/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1195 - acc: 0.0000e+00 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
      "Epoch 97/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1182 - acc: 0.0000e+00 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
      "Epoch 98/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.1167 - acc: 0.0000e+00 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
      "Epoch 99/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.1152 - acc: 0.0000e+00 - val_loss: 0.1072 - val_acc: 0.0000e+00\n",
      "Epoch 100/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.1138 - acc: 0.0000e+00 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
      "Epoch 101/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.1123 - acc: 0.0000e+00 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
      "Epoch 102/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.1108 - acc: 0.0000e+00 - val_loss: 0.1037 - val_acc: 0.0000e+00\n",
      "Epoch 103/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.1094 - acc: 0.0000e+00 - val_loss: 0.1025 - val_acc: 0.0000e+00\n",
      "Epoch 104/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.1079 - acc: 0.0000e+00 - val_loss: 0.1011 - val_acc: 0.0000e+00\n",
      "Epoch 105/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.1063 - acc: 0.0000e+00 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
      "Epoch 106/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.1048 - acc: 0.0000e+00 - val_loss: 0.0981 - val_acc: 0.0000e+00\n",
      "Epoch 107/600\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.1032 - acc: 0.0000e+00 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
      "Epoch 108/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.1017 - acc: 0.0000e+00 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
      "Epoch 109/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.1001 - acc: 0.0000e+00 - val_loss: 0.0935 - val_acc: 0.0000e+00\n",
      "Epoch 110/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0985 - acc: 0.0000e+00 - val_loss: 0.0919 - val_acc: 0.0000e+00\n",
      "Epoch 111/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0968 - acc: 0.0000e+00 - val_loss: 0.0903 - val_acc: 0.0000e+00\n",
      "Epoch 112/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0952 - acc: 0.0000e+00 - val_loss: 0.0887 - val_acc: 0.0000e+00\n",
      "Epoch 113/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0935 - acc: 0.0000e+00 - val_loss: 0.0870 - val_acc: 0.0000e+00\n",
      "Epoch 114/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0917 - acc: 0.0000e+00 - val_loss: 0.0852 - val_acc: 0.0000e+00\n",
      "Epoch 115/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0900 - acc: 0.0000e+00 - val_loss: 0.0833 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0882 - acc: 0.0000e+00 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
      "Epoch 117/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0864 - acc: 0.0000e+00 - val_loss: 0.0791 - val_acc: 0.0000e+00\n",
      "Epoch 118/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0845 - acc: 0.0000e+00 - val_loss: 0.0770 - val_acc: 0.0000e+00\n",
      "Epoch 119/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0826 - acc: 0.0000e+00 - val_loss: 0.0750 - val_acc: 0.0000e+00\n",
      "Epoch 120/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0807 - acc: 0.0000e+00 - val_loss: 0.0729 - val_acc: 0.0000e+00\n",
      "Epoch 121/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0788 - acc: 0.0000e+00 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
      "Epoch 122/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0768 - acc: 0.0000e+00 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
      "Epoch 123/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0748 - acc: 0.0000e+00 - val_loss: 0.0665 - val_acc: 0.0000e+00\n",
      "Epoch 124/600\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0753 - acc: 0.0000e+0 - 0s 288us/step - loss: 0.0727 - acc: 0.0000e+00 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
      "Epoch 125/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0706 - acc: 0.0000e+00 - val_loss: 0.0620 - val_acc: 0.0000e+00\n",
      "Epoch 126/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
      "Epoch 127/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0662 - acc: 0.0000e+00 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
      "Epoch 128/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0640 - acc: 0.0000e+00 - val_loss: 0.0552 - val_acc: 0.0000e+00\n",
      "Epoch 129/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0616 - acc: 0.0000e+00 - val_loss: 0.0528 - val_acc: 0.0000e+00\n",
      "Epoch 130/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0593 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0000e+00\n",
      "Epoch 131/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0569 - acc: 0.0000e+00 - val_loss: 0.0481 - val_acc: 0.0000e+00\n",
      "Epoch 132/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0544 - acc: 0.0000e+00 - val_loss: 0.0456 - val_acc: 0.0000e+00\n",
      "Epoch 133/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0000e+00\n",
      "Epoch 134/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0493 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0000e+00\n",
      "Epoch 135/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 136/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0439 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 137/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 138/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 139/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 140/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 141/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 142/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 143/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 144/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 145/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 146/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 147/600\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 148/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 149/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 150/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 151/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
      "Epoch 152/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 153/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 154/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00\n",
      "Epoch 155/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
      "Epoch 156/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 157/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 158/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
      "Epoch 159/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 160/600\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 161/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0218 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
      "Epoch 162/600\n",
      "80/80 [==============================] - 0s 349us/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
      "Epoch 163/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
      "Epoch 164/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0000e+00\n",
      "Epoch 165/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
      "Epoch 166/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0206 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
      "Epoch 167/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
      "Epoch 168/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0202 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0000e+00\n",
      "Epoch 169/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Epoch 170/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00\n",
      "Epoch 171/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 172/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00\n",
      "Epoch 174/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Epoch 175/600\n",
      "80/80 [==============================] - 0s 462us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00\n",
      "Epoch 176/600\n",
      "80/80 [==============================] - 0s 400us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0000e+00\n",
      "Epoch 177/600\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
      "Epoch 178/600\n",
      "80/80 [==============================] - 0s 400us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
      "Epoch 179/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 180/600\n",
      "80/80 [==============================] - 0s 425us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
      "Epoch 181/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
      "Epoch 182/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
      "Epoch 183/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 184/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 185/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
      "Epoch 186/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
      "Epoch 187/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
      "Epoch 188/600\n",
      "80/80 [==============================] - 0s 413us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
      "Epoch 189/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
      "Epoch 190/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
      "Epoch 191/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0000e+00\n",
      "Epoch 192/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
      "Epoch 193/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0000e+00\n",
      "Epoch 194/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0181 - val_acc: 0.0000e+00\n",
      "Epoch 195/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0000e+00\n",
      "Epoch 196/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0177 - val_acc: 0.0000e+00\n",
      "Epoch 197/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0175 - val_acc: 0.0000e+00\n",
      "Epoch 198/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0174 - val_acc: 0.0000e+00\n",
      "Epoch 199/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
      "Epoch 200/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
      "Epoch 201/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 202/600\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
      "Epoch 203/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
      "Epoch 204/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 205/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0170 - val_acc: 0.0000e+00\n",
      "Epoch 206/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
      "Epoch 207/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
      "Epoch 208/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
      "Epoch 209/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
      "Epoch 210/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
      "Epoch 211/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
      "Epoch 212/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0166 - val_acc: 0.0000e+00\n",
      "Epoch 213/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
      "Epoch 214/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
      "Epoch 215/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
      "Epoch 216/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
      "Epoch 217/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
      "Epoch 218/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0164 - val_acc: 0.0000e+00\n",
      "Epoch 219/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
      "Epoch 220/600\n",
      "80/80 [==============================] - 0s 400us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 221/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
      "Epoch 222/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0165 - val_acc: 0.0000e+00\n",
      "Epoch 223/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0164 - val_acc: 0.0000e+00\n",
      "Epoch 224/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
      "Epoch 225/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 226/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
      "Epoch 227/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 228/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 229/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0161 - val_acc: 0.0000e+00\n",
      "Epoch 230/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 325us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 231/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
      "Epoch 232/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 233/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
      "Epoch 234/600\n",
      "80/80 [==============================] - 0s 400us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 235/600\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0155 - val_acc: 0.0000e+00\n",
      "Epoch 236/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0155 - val_acc: 0.0000e+00\n",
      "Epoch 237/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
      "Epoch 238/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 239/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
      "Epoch 240/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 241/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
      "Epoch 242/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
      "Epoch 243/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
      "Epoch 244/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
      "Epoch 245/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 246/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 247/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
      "Epoch 248/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
      "Epoch 249/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 250/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 251/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
      "Epoch 252/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
      "Epoch 253/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 254/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
      "Epoch 255/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
      "Epoch 256/600\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 257/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
      "Epoch 258/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
      "Epoch 259/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 260/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 261/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
      "Epoch 262/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 263/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
      "Epoch 264/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 265/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
      "Epoch 266/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
      "Epoch 267/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 268/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 269/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 270/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
      "Epoch 271/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
      "Epoch 272/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
      "Epoch 273/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
      "Epoch 274/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
      "Epoch 275/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 276/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
      "Epoch 277/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 278/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
      "Epoch 279/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 280/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
      "Epoch 281/600\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
      "Epoch 282/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 283/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
      "Epoch 284/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 285/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
      "Epoch 286/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 287/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 238us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 288/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 289/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 290/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
      "Epoch 291/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 292/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
      "Epoch 293/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
      "Epoch 294/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 295/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
      "Epoch 296/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
      "Epoch 297/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 298/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 299/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 300/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
      "Epoch 301/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 302/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 303/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 304/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 305/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 306/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
      "Epoch 307/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 308/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 309/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 310/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 311/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 312/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 313/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 314/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
      "Epoch 315/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
      "Epoch 316/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 317/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
      "Epoch 318/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
      "Epoch 319/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
      "Epoch 320/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
      "Epoch 321/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0131 - val_acc: 0.0000e+00\n",
      "Epoch 322/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 323/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 324/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 325/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 326/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 327/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 328/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 329/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 330/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 331/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 332/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 333/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 334/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 335/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
      "Epoch 336/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 337/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 338/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Epoch 339/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 340/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 341/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
      "Epoch 342/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 343/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Epoch 344/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 350us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 345/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 346/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 347/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 348/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 349/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 350/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 351/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 352/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 353/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 354/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 355/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 356/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 357/600\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 358/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
      "Epoch 359/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 360/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 361/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 362/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
      "Epoch 363/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 364/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 365/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 366/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Epoch 367/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 368/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 369/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 370/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 371/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 372/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 373/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 374/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 375/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Epoch 376/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 377/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 378/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Epoch 379/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Epoch 380/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
      "Epoch 381/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
      "Epoch 382/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 383/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Epoch 384/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 385/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 386/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Epoch 387/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 388/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
      "Epoch 389/600\n",
      "80/80 [==============================] - 0s 387us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 390/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0103 - acc: 0.0000e+00 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
      "Epoch 391/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 392/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 393/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 394/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 395/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 396/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
      "Epoch 397/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0100 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 398/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0100 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 399/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0102 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 400/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Epoch 401/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 238us/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Epoch 402/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 403/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0100 - acc: 0.0000e+00 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
      "Epoch 404/600\n",
      "80/80 [==============================] - 0s 450us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 405/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 406/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0100 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 407/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Epoch 408/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 409/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 410/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 411/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 412/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 413/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0099 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 414/600\n",
      "80/80 [==============================] - 0s 487us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 415/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 416/600\n",
      "80/80 [==============================] - 0s 425us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 417/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 418/600\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.0000e+0 - 0s 450us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
      "Epoch 419/600\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 420/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 421/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 422/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Epoch 423/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 424/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 425/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 426/600\n",
      "80/80 [==============================] - 0s 425us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 427/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
      "Epoch 428/600\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0096 - acc: 0.0000e+00 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
      "Epoch 429/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
      "Epoch 430/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0095 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 431/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 432/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0100 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 433/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0095 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 434/600\n",
      "80/80 [==============================] - 0s 388us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 435/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 436/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 437/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0095 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 438/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0097 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 439/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 440/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
      "Epoch 441/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
      "Epoch 442/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 443/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 444/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 445/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
      "Epoch 446/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
      "Epoch 447/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 448/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 449/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 450/600\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.0000e+0 - 0s 275us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 451/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 452/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 453/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 454/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
      "Epoch 455/600\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 456/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 457/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 459/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0092 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 460/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 461/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 462/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 463/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 464/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 465/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0090 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 466/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 467/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
      "Epoch 468/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
      "Epoch 469/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0090 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 470/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 471/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0090 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 472/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 473/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 474/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 475/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0090 - acc: 0.0000e+00 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
      "Epoch 476/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 477/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 478/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 479/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0090 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 480/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0090 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 481/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 482/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 483/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 484/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 485/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 486/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 487/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 488/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 489/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 490/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 491/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 492/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 493/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
      "Epoch 494/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 495/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 496/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 497/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 498/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 499/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 500/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 501/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 502/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 503/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 504/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
      "Epoch 505/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 506/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0087 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 507/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 508/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 509/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 510/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 511/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 512/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 513/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 514/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 515/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 262us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 516/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 517/600\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 518/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 519/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 520/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 521/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 522/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
      "Epoch 523/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 524/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 525/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 526/600\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Epoch 527/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 528/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 529/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 530/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 531/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Epoch 532/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0084 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 533/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 534/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 535/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 536/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 537/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 538/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 539/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 540/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 541/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 542/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 543/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0083 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 544/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 545/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 546/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 547/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 548/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 549/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 550/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 551/600\n",
      "80/80 [==============================] - 0s 313us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 552/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 553/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 554/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 555/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 556/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 557/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 558/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 559/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 560/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 561/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 562/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 563/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 564/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 565/600\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
      "Epoch 566/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 567/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 568/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 569/600\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 570/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 571/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0080 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 572/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 300us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 573/600\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
      "Epoch 574/600\n",
      "80/80 [==============================] - 0s 425us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 575/600\n",
      "80/80 [==============================] - 0s 375us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 576/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Epoch 577/600\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.0000e+0 - 0s 300us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 578/600\n",
      "80/80 [==============================] - 0s 413us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 579/600\n",
      "80/80 [==============================] - 0s 363us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 580/600\n",
      "80/80 [==============================] - 0s 362us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 581/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Epoch 582/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 583/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 584/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 585/600\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 586/600\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 587/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 588/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
      "Epoch 589/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 590/600\n",
      "80/80 [==============================] - 0s 350us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 591/600\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Epoch 592/600\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 593/600\n",
      "80/80 [==============================] - 0s 288us/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 594/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 595/600\n",
      "80/80 [==============================] - 0s 300us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
      "Epoch 596/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 597/600\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 598/600\n",
      "80/80 [==============================] - 0s 413us/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
      "Epoch 599/600\n",
      "80/80 [==============================] - 0s 338us/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
      "Epoch 600/600\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0095 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train, y_train, epochs = 600, validation_data = (X_test,y_test))\n",
    "\n",
    "# Predicting values with test data\n",
    "results = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f3c1052588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the output\n",
    "plt.scatter(range(20), results, c='r')\n",
    "plt.scatter(range(20), y_test, c = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val= np.zeros_like(y_test)\n",
    "average = 0\n",
    "for i in range(len(y_test)):\n",
    "    val[i] = np.absolute(y_test[i] - results[i])\n",
    "    average += val[i]\n",
    "    y_test[i] *= 150\n",
    "    results[i] *= 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 99.99053647071123\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy = \" + str(100 - average/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
